<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BrainSeg AI - Neural Segmentation Research</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <style>
        :root {
            --primary: #6B46C1;
            --primary-dark: #553C9A;
            --dark: #111111;
            --darker: #000000;
            --light: #F9FAFB;
            --gray: #4A5568;
            --gray-light: #A0AEC0;
        }
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: var(--light);
            background-color: var(--dark);
        }
        
        .container {
            width: 90%;
            max-width: 1200px;
            margin: 0 auto;
            padding: 1rem;
        }
        
        header {
            background-color: var(--darker);
            padding: 3rem 0;
            position: relative;
            overflow: hidden;
        }
        
        header::after {
            content: "";
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: linear-gradient(135deg, var(--primary-dark) 0%, transparent 70%);
            opacity: 0.4;
            z-index: 1;
        }
        
        header .container {
            position: relative;
            z-index: 2;
        }
        
        nav {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1.5rem 0;
        }
        
        .logo {
            font-size: 1.5rem;
            font-weight: 700;
            display: flex;
            align-items: center;
        }
        
        .logo span {
            color: var(--primary);
        }
        
        .nav-links {
            display: flex;
            list-style: none;
        }
        
        .nav-links li {
            margin-left: 2rem;
        }
        
        .nav-links a {
            color: var(--light);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        
        .nav-links a:hover {
            color: var(--primary);
        }
        
        .hero {
            padding: 4rem 0;
            text-align: center;
        }
        
        #brain-container {
            width: 250px;
            height: 250px;
            margin: 0 auto 2rem auto;
            position: relative;
        }
        
        #brain-model {
            width: 100%;
            height: 100%;
        }
        
        h1 {
            font-size: 2.6rem;
            line-height: 1.2;
            margin-bottom: 1.5rem;
            background: linear-gradient(90deg, #fff, var(--primary));
            -webkit-background-clip: text;
            background-clip: text;
            color: transparent;
        }
        
        .tagline {
            font-size: 1.2rem;
            color: var(--gray-light);
            margin-bottom: 2rem;
            max-width: 800px;
            margin-left: auto;
            margin-right: auto;
        }
        
        .btn {
            display: inline-block;
            background-color: var(--primary);
            color: white;
            padding: 0.75rem 1.75rem;
            text-decoration: none;
            border-radius: 4px;
            font-weight: 600;
            transition: all 0.3s ease;
            border: none;
            cursor: pointer;
        }
        
        .btn:hover {
            background-color: var(--primary-dark);
            transform: translateY(-2px);
            box-shadow: 0 10px 15px rgba(85, 60, 154, 0.2);
        }
        
        section {
            padding: 5rem 0;
        }
        
        section:nth-child(even) {
            background-color: var(--darker);
        }
        
        h2 {
            font-size: 2rem;
            margin-bottom: 2rem;
            position: relative;
            display: inline-block;
            color: var(--light);
        }
        
        h2::after {
            content: "";
            position: absolute;
            left: 0;
            bottom: -10px;
            height: 4px;
            width: 60px;
            background-color: var(--primary);
        }
        
        .methodology-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2rem;
            margin-top: 3rem;
        }
        
        .method-card {
            background-color: rgba(0, 0, 0, 0.2);
            border-radius: 8px;
            overflow: hidden;
            transition: all 0.3s ease;
            border: 1px solid rgba(107, 70, 193, 0.2);
        }
        
        .method-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 30px rgba(0, 0, 0, 0.3);
            border-color: var(--primary);
        }
        
        .method-header {
            background-color: var(--primary-dark);
            padding: 1.5rem;
            text-align: center;
        }
        
        .method-content {
            padding: 1.5rem;
        }
        
        .method-content ul {
            list-style-position: inside;
            margin-top: 1rem;
        }
        
        .method-content li {
            margin-bottom: 0.5rem;
            position: relative;
            padding-left: 1.2rem;
        }
        
        .method-content li:before {
            content: "•";
            color: var(--primary);
            position: absolute;
            left: 0;
        }
        
        .results-container {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 3rem;
            margin-top: 3rem;
        }
        
        .result-img {
            width: 100%;
            border-radius: 8px;
            transition: all 0.3s ease;
        }
        
        .result-img:hover {
            transform: scale(1.02);
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.4);
        }
        
        .stats {
            margin-top: 3rem;
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 2rem;
            text-align: center;
        }
        
        .stat-card {
            background-color: rgba(0, 0, 0, 0.2);
            padding: 2rem;
            border-radius: 8px;
            transition: all 0.3s ease;
            border: 1px solid rgba(107, 70, 193, 0.2);
        }
        
        .stat-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 30px rgba(0, 0, 0, 0.3);
            border-color: var(--primary);
        }
        
        .stat-value {
            font-size: 2.5rem;
            font-weight: bold;
            color: var(--primary);
            margin-bottom: 0.5rem;
        }
        
        .stat-label {
            color: var(--gray-light);
            font-size: 1rem;
        }
        
        .faq {
            max-width: 800px;
            margin: 3rem auto 0;
        }
        
        .faq-item {
            margin-bottom: 1.5rem;
            border-bottom: 1px solid rgba(107, 70, 193, 0.2);
            padding-bottom: 1.5rem;
        }
        
        .faq-question {
            font-size: 1.2rem;
            font-weight: 600;
            margin-bottom: 0.75rem;
            color: var(--light);
            cursor: pointer;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        
        .faq-question:hover {
            color: var(--primary);
        }
        
        .faq-answer {
            color: var(--gray-light);
        }
        
        footer {
            background-color: var(--darker);
            padding: 3rem 0;
            text-align: center;
            position: relative;
        }
        
        footer::before {
            content: "";
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 5px;
            background: linear-gradient(90deg, var(--primary-dark), var(--primary), var(--primary-dark));
        }
        
        .contact-info {
            margin-top: 1.5rem;
            color: var(--gray-light);
        }
        
        .contact-info a {
            color: var(--primary);
            text-decoration: none;
            transition: color 0.3s ease;
        }
        
        .contact-info a:hover {
            color: var(--light);
        }
        
        .team-members {
            font-style: italic;
            color: var(--gray-light);
            margin-top: 1rem;
        }
        
        /* Responsive adjustments */
        @media (max-width: 768px) {
            .nav-links {
                display: none;
            }
            
            h1 {
                font-size: 2rem;
            }
            
            .results-container {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <nav>
                <div class="logo">Brain<span>Seg</span> AI</div>
                <ul class="nav-links">
                    <li><a href="#about">About</a></li>
                    <li><a href="#methodology">Methodology</a></li>
                    <li><a href="#results">Results</a></li>
                    <li><a href="#faq">FAQ</a></li>
                </ul>
            </nav>
            
            <div class="hero">
                <div id="brain-container">
                    <div id="brain-model"></div>
                </div>
                <h1>From Man to Machine: Advanced Brain Segmentation AI</h1>
                <p class="tagline">A comparative study of manual vs AI-based segmentation techniques that achieves superior performance through our innovative i-UNet architecture</p>
                <a href="#methodology" class="btn">Explore Our Research</a>
            </div>
        </div>
    </header>
    
    <main>
        <section id="about" class="container">
            <h2>Our Research</h2>
            <p>Manual segmentation, while considered the gold standard in medical image processing, is known to be very time-consuming (~4 hours) and can induce inter-observer variability. Our research demonstrates how the improved U-Net architecture (i-UNet) reduces segmentation time to under 30 minutes while maintaining exceptional accuracy.</p>
            
            <div class="stats">
                <div class="stat-card">
                    <div class="stat-value">0.99</div>
                    <div class="stat-label">i-UNet Dice Score</div>
                </div>
                
                <div class="stat-card">
                    <div class="stat-value">0.01</div>
                    <div class="stat-label">i-UNet Loss</div>
                </div>
                
                <div class="stat-card">
                    <div class="stat-value">&lt;10</div>
                    <div class="stat-label">Hausdorff Distance</div>
                </div>
                
                <div class="stat-card">
                    <div class="stat-value">8×</div>
                    <div class="stat-label">Faster than Manual</div>
                </div>
            </div>
        </section>
        
        <section id="methodology">
            <div class="container">
                <h2>Methodology</h2>
                <p>Our approach compares state-of-the-art AI-based segmentation against traditional manual techniques, with a focus on improving both speed and accuracy.</p>
                
                <div class="methodology-grid">
                    <div class="method-card">
                        <div class="method-header">
                            <h3>Manual Segmentation</h3>
                        </div>
                        <div class="method-content">
                            <ul>
                                <li>Slice by slice manual segmentation</li>
                                <li>Variation of software using ITK-SNAP & 3D Slicer</li>
                                <li>High precision but time-intensive</li>
                                <li>Subject to inter-observer variability</li>
                            </ul>
                        </div>
                    </div>
                    
                    <div class="method-card">
                        <div class="method-header">
                            <h3>i-UNet Architecture</h3>
                        </div>
                        <div class="method-content">
                            <ul>
                                <li>Attention-based mechanisms</li>
                                <li>ResNet50 backbone for feature extraction</li>
                                <li>Optimized for minimal loss</li>
                                <li>Trained on SynthStrip dataset</li>
                            </ul>
                        </div>
                    </div>
                    
                    <div class="method-card">
                        <div class="method-header">
                            <h3>3D Reconstruction</h3>
                        </div>
                        <div class="method-content">
                            <ul>
                                <li>Marching cubes algorithm</li>
                                <li>High-fidelity 3D modeling</li>
                                <li>Precise brain fold rendering</li>
                                <li>Comprehensive structural visualization</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        
        <section id="results" class="container">
            <h2>Results</h2>
            <p>Our i-UNet architecture demonstrates superior performance across all metrics compared to standard U-Net and manual segmentation approaches.</p>
            
            <div class="results-container">
                <div>
                    <img src="/api/placeholder/500/300" alt="Brain segmentation visualization" class="result-img">
                </div>
                <div>
                    <img src="/api/placeholder/500/300" alt="Performance metrics visualization" class="result-img">
                </div>
            </div>
            
            <p style="margin-top: 2rem;">The i-UNet achieved a final loss of 0.01 compared to UNet's 0.49, showcasing faster convergence and better optimization with minimal overfitting. The Dice score for i-UNet consistently reached 0.99, while standard UNet stabilized around 0.98. Most importantly, i-UNet maintained stable performance across all validation tests, proving its robustness and reliability for clinical applications.</p>
        </section>
        
        <section id="faq">
            <div class="container">
                <h2>FAQ</h2>
                <div class="faq">
                    <div class="faq-item">
                        <div class="faq-question">
                            What advantage does i-UNet have over standard U-Net?
                        </div>
                        <div class="faq-answer">
                            Our i-UNet architecture incorporates attention mechanisms and a ResNet50 backbone that significantly improves segmentation accuracy and reduces computational cost. This results in faster convergence (0.01 final loss vs. 0.49), higher Dice scores (0.99 vs. 0.98), and more precise boundary delineation with lower Hausdorff distances.
                        </div>
                    </div>
                    
                    <div class="faq-item">
                        <div class="faq-question">
                            How much faster is AI-based segmentation compared to manual techniques?
                        </div>
                        <div class="faq-answer">
                            Manual segmentation typically takes around 4 hours per brain scan, while our i-UNet architecture completes the same task in under 30 minutes—approximately 8 times faster. This dramatic improvement in processing time makes high-quality brain segmentation more accessible for clinical applications.
                        </div>
                    </div>
                    
                    <div class="faq-item">
                        <div class="faq-question">
                            What dataset was used for training and validation?
                        </div>
                        <div class="faq-answer">
                            We utilized the SynthStrip dataset, which is specifically designed for brain image processing. This comprehensive dataset provided the necessary diversity of MRI T1 scans required to train our models effectively and ensure robust performance across various brain anatomies.
                        </div>
                    </div>
                    
                    <div class="faq-item">
                        <div class="faq-question">
                            What software was used for the manual segmentation?
                        </div>
                        <div class="faq-answer">
                            We performed manual segmentations using two industry-standard software packages: ITK-SNAP and 3D Slicer. This allowed us to compare the performance of different manual segmentation approaches and establish a comprehensive baseline for evaluating our AI-based methods.
                        </div>
                    </div>
                    
                    <div class="faq-item">
                        <div class="faq-question">
                            What are the next steps for this research?
                        </div>
                        <div class="faq-answer">
                            Our future work includes implementing Grad-CAM visualizations to better understand the model's decision-making process, optimizing the Marching Cubes algorithm for more precise 3D reconstructions, and exploring metric-based learning approaches to address limitations in open-access data. We're also conducting usability studies with various segmentation software tools.
                        </div>
                    </div>
                </div>
            </div>
        </section>
    </main>
    
    <footer>
        <div class="container">
            <div class="logo" style="justify-content: center;">Brain<span>Seg</span> AI</div>
            <div class="team-members">
                A research project by Balvinder Kaur Dhillon, Róza Rebeka Somogyi, Abbas Abdirashid Mahmud Yusuf, Vivek Kesava Christopher Kindell, Kirijan Nalvelnathan
            </div>
            <div class="contact-info">
                <p>Supervised by Professor Zion Tse & Dr. S.M.Hadi Sadati</p>
                <p>© 2025 BrainSeg Research Team</p>
            </div>
        </div>
    </footer>
    <script>
        // Three.js setup for spinning brain
        document.addEventListener('DOMContentLoaded', function() {
            // Create scene
            const scene = new THREE.Scene();
            
            // Create camera
            const camera = new THREE.PerspectiveCamera(75, 1, 0.1, 1000);
            camera.position.z = 5;
            
            // Create renderer
            const renderer = new THREE.WebGLRenderer({ alpha: true, antialias: true });
            renderer.setSize(250, 250);
            renderer.setClearColor(0x000000, 0);
            
            // Add renderer to DOM
            const container = document.getElementById('brain-model');
            container.appendChild(renderer.domElement);
            
            // Create brain geometry
            const brainGeometry = new THREE.SphereGeometry(1.5, 32, 32);
            
            // Create brain material with purple color and slight transparency
            const brainMaterial = new THREE.MeshPhongMaterial({
                color: 0x6B46C1,
                transparent: true,
                opacity: 0.9,
                shininess: 100
            });
            
            // Create brain mesh
            const brain = new THREE.Mesh(brainGeometry, brainMaterial);
            
            // Add complexity to brain to make it look less like a perfect sphere
            const bumps = 10;
            for (let i = 0; i < bumps; i++) {
                const bumpGeometry = new THREE.SphereGeometry(0.25 + Math.random() * 0.2, 16, 16);
                const bump = new THREE.Mesh(bumpGeometry, brainMaterial);
                
                const theta = Math.random() * Math.PI * 2;
                const phi = Math.acos(2 * Math.random() - 1);
                
                const x = 1.2 * Math.sin(phi) * Math.cos(theta);
                const y = 1.2 * Math.sin(phi) * Math.sin(theta);
                const z = 1.2 * Math.cos(phi);
                
                bump.position.set(x, y, z);
                brain.add(bump);
            }
            
            // Add brain to scene
            scene.add(brain);
            
            // Add some sulci (brain folds) with curve geometries
            const curveCount = 8;
            for (let i = 0; i < curveCount; i++) {
                // Create a random curve on the surface of the brain
                const points = [];
                const segments = 10;
                const radius = 1.6;
                
                const startAngle = Math.random() * Math.PI * 2;
                const angleWidth = (0.5 + Math.random() * 0.5) * Math.PI;
                
                for (let j = 0; j <= segments; j++) {
                    const angle = startAngle + (j / segments) * angleWidth;
                    const x = radius * Math.sin(angle) * Math.cos(j/segments * Math.PI);
                    const y = radius * Math.sin(angle) * Math.sin(j/segments * Math.PI);
                    const z = radius * Math.cos(angle);
                    
                    points.push(new THREE.Vector3(x, y, z));
                }
                
                const curve = new THREE.CatmullRomCurve3(points);
                const tubeGeometry = new THREE.TubeGeometry(curve, 20, 0.05, 8, false);
                const tubeMaterial = new THREE.MeshPhongMaterial({
                    color: 0x553C9A,
                    shininess: 50
                });
                
                const tube = new THREE.Mesh(tubeGeometry, tubeMaterial);
                scene.add(tube);
            }
            
            // Add lighting
            const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
            scene.add(ambientLight);
            
            const light1 = new THREE.DirectionalLight(0xffffff, 0.8);
            light1.position.set(5, 5, 5);
            scene.add(light1);
            
            const light2 = new THREE.DirectionalLight(0x6B46C1, 0.5);
            light2.position.set(-5, -5, -5);
            scene.add(light2);
            
            // Animation loop
            function animate() {
                requestAnimationFrame(animate);
                
                // Rotate brain
                brain.rotation.y += 0.005;
                brain.rotation.x += 0.002;
                brain.rotation.z += 0.001;
                
                // Render scene
                renderer.render(scene, camera);
            }
            
            animate();
            
            // Handle window resize
            window.addEventListener('resize', function() {
                // Keep aspect ratio 1:1 for the brain
                const size = Math.min(250, window.innerWidth * 0.8);
                renderer.setSize(size, size);
            });
        });
    </script>
</body>
</html>
